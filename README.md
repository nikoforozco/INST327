# INST 327: Database Modeling and Design
Project Diary and Report
05/15/2023
Team 7 - Jay Caro, Vivian Chao, Rayn Carrillo, Nikolas F Orozco, Madison Diamond


# Introduction
Our team has conducted an analysis of crimes in Montgomery County, Maryland, in order to understand more about the safety and security of its residents. Our analysis focused on understanding specific locations and times when crime is most likely to occur. We have determined which areas within Montgomery County are more susceptible to crime, and which specific types of crime are more prevalent in certain areas. 
This information is important in determining the effectiveness of law enforcement presence, to reduce crime in the county. By analyzing our data, we can identify areas that are more or less secure, which can assist authorities in making public safety decisions. This information can be valuable for residents, businesses, and visitors who want to take precautions to avoid being victims of crime.
Our analysis of crime patterns in Montgomery County allows for more safety and security within this community. By examining crime trends across different police districts and neighborhoods, we have been able to highlight areas of concern. We believe that our findings can help create a safer and more secure environment for all residents of Montgomery County.

# Database Description
The database we are looking at explains crime data across Montgomery County, Maryland. The database examines crimes based on location, victims, police, and time. This data has allowed us to understand specific patterns in crime in this county. To do so, it is necessary to observe which locations (based on specific address data of address, city, state, zip code, and place) have the highest crime rates. Our database analysis has allowed us to better understand the occurrence of crimes in Montgomery County. 
Based on the different crime rates that we observe we have learned more about the safety of this community. Learning more about the specifics of crimes can help to prevent continued violations in the future.
The analysis of this data can improve the police force. In areas where crimes are more prevalent, Montgomery County officials and police resource officers can use this database to determine whether more funding or more officers are needed. The police force/police funding in Montgomery County may need to be reallocated based on the results of the crime rates and location in this county. 
Our database can also be used by advocacy groups and non-profits if they determine that a city or police district has a disproportionate amount of crime and policing. These data can be used by advocacy organizations and nonprofits to focus their efforts on reducing crime in specific areas and comparing locations.
We have gained valuable insights into the safety and security of Montgomery County through our analysis of crime patterns. It is our team's hope that the findings of this study will assist Montgomery County residents in creating a safer and more secure environment.

# Logical Design
Our method in creating a logical design was to group similar attributes into their respective tables, allowing us to create eight entities. By organizing all of the important attributes into their own groups, we were able to create a design that users will easily be able to navigate based on the entity names. For example, if exploring a certain crime, they would use our ‘crime’ entity to access all of the different crime types. If a user wanted to find a location, they would use the ‘location’ entity to analyze a certain block address or zip code. 
Additionally, if a user was interested in a crime that occurred in a specific location, they would be able to easily find this information by joining our linking table, ‘crime_location’ to the entities by calling their respective primary/foreign keys. The ‘crime_id’ foreign key can be found in all of the linking tables in order for users to connect the ‘victims,’ ‘location,’ and ‘police’ entities with the ‘crime’ entity, as that table contains ‘crime_id’ as its primary key and describes what crime occurred.
In regards to the relationships between the entities, we made one-to-many relationships, where the main/non-linking tables acted as the parent tables, and the linking entities acted as the child tables. Furthermore, we chose their data types based on how the data was given in the original .csv file, where attributes that contained strings would be assigned as VARCHAR() and attributes with numbers would be assigned as INT. The ‘zip_code’ entity is an exception to being labeled as an INT, and is instead labeled as VARCHAR() to avoid the zip codes being used in an equation. We also made sure that all primary keys were stored as auto-incrementing and non-null, in order for users to be able to successfully use the database without facing primary keys with null values.
Physical Database
When designing our physical database, we didn't have time to make more tables than we already had to work with. Luckily, with the way we had designed our ERD, it didn't take long to create the database itself. What we attempted to create was a section of the dataset that could answer where crime was the worst. Not just the frequency, but types of crime and times it was occurring. We wanted to make something that professionals could see the impact and try to answer the “Why is this happening?”. To ensure we were getting the most pertinent data, we checked through as much identifying information as we could. Once most of the superfluous or less useful data was scrubbed, we were left with 8 tables to use. Our target audience like governing officials and statisticians needed identifiers like police information or sector in order to see where the crime density was located. That paired with when crimes were happening and when, could help interested parties in determining how to prevent or solve crime problems in these areas. We also wanted anyone with access to the database to be able to create their own views and queries. 

# Sample Data
After realizing that over 300,000 data points were far too much to try to iterate over, we needed to cut it down. In the end, we decided on 966 samples to give us a snapshot of the crime statistics.  If the section of data we used gave us results that had patterns, we could point to that as a subject of interest, and continue expanding upon the queries after adding more. Below is a picture of our crime table (with the data we decided to keep). As we wanted to get the best picture of what is going on with crime in Montgomery County, we tried to keep as much detail as possible so as not to skew the results.

# Questions we were able to answer
What crime occurs the most?  
Where do most crimes occur? (outdoors, inside residences, etc.)  
Are crimes more likely to be committed at certain times?  (00:00 to 11:59, 12:00 to 17:59, 18:00 to 23:59)  
What places have more crime than others?    
How many victims were there per crime per month?  

# The following list describes what each query we wrote for our database displays: 
Query 1: Creates a view that shows the most committed crime and amount of times it was committed
Query 2: Creates a view that shows the setting with the most crimes committed
Query 3: Displays the number of incidents for each time of the day  (i.e morning, afternoon, evening)
Query 4: Displays the city with the highest crime and its total number of incidents 
Query 5: Displays total number of victims per month for each crime
Query 6: Displays a summary table listing each CR_incident, crime and address

# Changes from original design
Since developing our original design, our group has made multiple modifications to our database by revising our entities and attributes. One of the major changes from our original design includes creating a new entity, ‘crime_police.’ This entity is used as a linking table between our ‘crime’ and ‘police’ entities to describe their close relationship. Our team has also chosen to move our ‘sector’ attribute from ‘location’ to the ‘police’ entity because it would be more logical for ‘sector’ to be describing the specific areas that the police are responsible for, rather than the location of the crime. We have also reviewed and changed the data types and storage to describe our attributes more appropriately. Additionally, we changed our ‘incident_id’ attribute to ‘crime_id,’ as the database refers to the name ‘crime,’ rather than ‘incident,’ making the database more cohesive, especially for users other than ourselves. Furthermore, rather than using the entire dataset in the given .csv file, which had over 300,000 records, we limited ourselves to crimes that occurred in 2023, which allows us to work with less than 1,000 sample records.

# Database Ethics Considerations
When beginning the development of our project, our group considered a handful of database ethical considerations. Starting with diversity, equity, and inclusion, we suspect that the lack of background information about the crimes can lead our audience to either overestimate or underestimate the crimes that take place in the county, causing them to act improperly, such as media exaggeration. Additionally, we found that failing to share the funding received by each police district may cause us to undermine how safe these areas really are because of the assumption that each city is properly funded to protect its citizens. In regard to data privacy, fair use, and other ethical considerations, we believe that because our data comes from a governmental and public source, where no personal data about victims or perpetrators are shared, the database is unlikely to result in privacy violations. While it is possible that certain crimes located in residential areas could potentially lead to compromised privacy, the risk is minimal due to the broad information that the database stores (e.g., no description of what was stolen in a house robbery).
Based on all of these ethical considerations, our project faces little to no impact from what was considered. While the DEI concerns can impact our audience’s perception of the crimes in the county, failing to address what crimes occurred, where they took place, and when they began/ended can lead to even greater problems, such as underestimating their own safety. Additionally, without the information about the crime, there would be no database in the first place. This idea can be applied to our data privacy, fair use, and other ethical considerations dilemma, where concealing any location information about the crime could cause greater harm than sharing the information, especially when the data is already broad.

# Lessons Learned
First and foremost, we learned we needed to start sooner. I think some misunderstanding about the scope of the work led us to a bit of a rush on our part towards the end, especially as it came to our questions. Our communication wasn't always what it needed to be, and oftentimes we relied on intuition to ensure that work was getting done by our fellow members rather than talking about it. We needed to come up with a written game plan for how the design and report were going to go, and we dropped the ball on that. Towards the latter part of the project, we realized some of our database was throwing errors we had not previously seen, so it was a bit of a rush to fix that towards the end. Putting more eyes on each part of the project instead of just relying on the person responsible for creating it for quality control would have been more helpful. Getting work done early would have definitely helped us with the stress and scramble toward the end of the project.

# Potential Future Work
Looking towards the future, we had a lot that we wish we could've done with this database that we just ran out of time for. Out of the ten questions that we started with, we were only able to answer five, plus a sixth that was relevant to an existing query. With the restriction of nearly 1000 data points, we also wished we had the time to expand to the entire data set. As we found patterns in the 2023 data we used, it warrants further research into why Silver Spring has the most amount of crime for our sample data. Even using the same queries and view, but with different samples could potentially lead to conclusions or open other lines of inquiry. What we wanted to do most that could've had potential impact was police station proximity or relative response times and whether these had an impact on crime. Whatever future work is done on this dataset, ensuring all angles are looked at for context needs to be a focus.
